# Azure End-to-End Data Engineering Project

Project Overview:

This project demonstrates an end-to-end Azure Data Engineering pipeline built using modern cloud data architecture principles. The solution follows the Medallion Architecture (Bronze ‚Üí Silver ‚Üí Gold) design pattern to ingest, transform, and serve data for analytics.

The pipeline automates data ingestion, transformation using PySpark, and loading into curated layers for reporting and analysis.

Architecture:

The project is implemented using the following Azure services:

  -> Azure Data Factory (ADF) ‚Äì Data ingestion & orchestration
  -> Azure Data Lake Storage Gen2 (ADLS) ‚Äì Data storage
  -> Azure Databricks ‚Äì Data transformation using PySpark
  -> Azure Synapse Analytics ‚Äì Querying curated data
  -> SQL ‚Äì Data validation & reporting

üîÑ Medallion Architecture

Bronze Layer
  Raw data ingestion from source
  Stored in ADLS Gen2
  Minimal transformation

Silver Layer
  Data cleansing
  Handling null values
  Data type standardization
  Business logic transformations

Gold Layer
  Aggregated and curated datasets
  Ready for analytics and reporting
  Optimized for querying
  
## ‚öô Technologies Used

- Azure Data Factory
- Azure Databricks (PySpark)
- Azure Data Lake Storage Gen2
- Azure Synapse Analytics
- GitHub

---
Project Workflow

1Ô∏è‚É£ Data is ingested into the Bronze layer using Azure Data Factory pipelines.
2Ô∏è‚É£ Azure Databricks processes raw data using PySpark transformations.
3Ô∏è‚É£ Cleaned data is written to the Silver layer.
4Ô∏è‚É£ Aggregated datasets are stored in the Gold layer.
5Ô∏è‚É£ Azure Synapse Analytics is used for querying and reporting.

Sample PySpark Transformation:

df = spark.read.format("csv") \
    .option("header", "true") \
    .load("/mnt/bronze/orders.csv")

df_clean = df.dropna() \
    .withColumnRenamed("orderID", "order_id")

df_clean.write.format("parquet") \
    .mode("overwrite") \
    .save("/mnt/silver/orders_clean")

Sample SQL Query (Gold Layer):
      SELECT customer_id,
           SUM(order_amount) AS total_spent
    FROM gold.orders
    GROUP BY customer_id;


Key Skills Demonstrated

‚úî ETL Pipeline Design
‚úî Cloud Data Engineering
‚úî PySpark Transformations
‚úî Azure Data Factory Orchestration
‚úî Data Lake Architecture
‚úî SQL Query Optimization
‚úî Medallion Architecture Implementation

---

## üìà Future Enhancements

- Incremental data load
- Data validation checks
- Monitoring & alerting
- CI/CD using Azure DevOps
